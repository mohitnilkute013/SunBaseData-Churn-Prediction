{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subscription_Length_Months</th>\n",
       "      <th>Monthly_Bill</th>\n",
       "      <th>Total_Usage_GB</th>\n",
       "      <th>Churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>33</td>\n",
       "      <td>Male</td>\n",
       "      <td>Houston</td>\n",
       "      <td>23</td>\n",
       "      <td>55.13</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>19</td>\n",
       "      <td>61.65</td>\n",
       "      <td>351</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>17</td>\n",
       "      <td>96.11</td>\n",
       "      <td>251</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>51</td>\n",
       "      <td>Female</td>\n",
       "      <td>New York</td>\n",
       "      <td>20</td>\n",
       "      <td>49.25</td>\n",
       "      <td>434</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>27</td>\n",
       "      <td>Female</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>19</td>\n",
       "      <td>76.57</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Age  Gender     Location  Subscription_Length_Months  Monthly_Bill  \\\n",
       "99995   33    Male      Houston                          23         55.13   \n",
       "99996   62  Female     New York                          19         61.65   \n",
       "99997   64    Male      Chicago                          17         96.11   \n",
       "99998   51  Female     New York                          20         49.25   \n",
       "99999   27  Female  Los Angeles                          19         76.57   \n",
       "\n",
       "       Total_Usage_GB  Churn  \n",
       "99995             226      1  \n",
       "99996             351      0  \n",
       "99997             251      1  \n",
       "99998             434      1  \n",
       "99999             173      1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(r'D:/Data Science/Job Assignments/SunBaseData/Data/customer_churn_large_dataset.xlsx')\n",
    "df.drop(['CustomerID', 'Name'], axis=1, inplace=True)\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[df.columns].drop(['Churn'], axis=True)\n",
    "y = df['Churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Subscription_Length_Months', 'Monthly_Bill', 'Total_Usage_GB'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define which columns should be onehot-encoded and which should be scaled\n",
    "categorical_cols = X.select_dtypes(include='object').columns\n",
    "numerical_cols = X.select_dtypes(exclude='object').columns\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # HAndling Feature Scaling\n",
    "from sklearn.preprocessing import OneHotEncoder # OneHot Encoding\n",
    "## pipelines\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is no feature engineering process we are doing with numerical columns like handling missing values, outliers detection, etc. \n",
    "# As we have seen in EDA, so we only do standardization \n",
    "\n",
    "## Numerical Pipeline\n",
    "num_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    # ('imputer',SimpleImputer(strategy='median')),\n",
    "    ('scaler',StandardScaler())\n",
    "\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "# Categorigal Pipeline\n",
    "cat_pipeline=Pipeline(\n",
    "    steps=[\n",
    "    # ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehotencoder',OneHotEncoder(sparse=False)),\n",
    "    ('scaler',StandardScaler(with_mean=False))\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "preprocessor=ColumnTransformer([\n",
    "('num_pipeline',num_pipeline,numerical_cols),\n",
    "('cat_pipeline',cat_pipeline,categorical_cols)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "X_train=pd.DataFrame(preprocessor.fit_transform(X_train),columns=preprocessor.get_feature_names_out())\n",
    "X_test=pd.DataFrame(preprocessor.transform(X_test),columns=preprocessor.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_pipeline__Age</th>\n",
       "      <th>num_pipeline__Subscription_Length_Months</th>\n",
       "      <th>num_pipeline__Monthly_Bill</th>\n",
       "      <th>num_pipeline__Total_Usage_GB</th>\n",
       "      <th>cat_pipeline__Gender_Female</th>\n",
       "      <th>cat_pipeline__Gender_Male</th>\n",
       "      <th>cat_pipeline__Location_Chicago</th>\n",
       "      <th>cat_pipeline__Location_Houston</th>\n",
       "      <th>cat_pipeline__Location_Los Angeles</th>\n",
       "      <th>cat_pipeline__Location_Miami</th>\n",
       "      <th>cat_pipeline__Location_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.243589</td>\n",
       "      <td>0.074501</td>\n",
       "      <td>1.632642</td>\n",
       "      <td>1.481066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.499063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.654284</td>\n",
       "      <td>-1.515230</td>\n",
       "      <td>0.336478</td>\n",
       "      <td>0.829765</td>\n",
       "      <td>2.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.492223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.785482</td>\n",
       "      <td>1.086147</td>\n",
       "      <td>0.027632</td>\n",
       "      <td>1.166909</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000033</td>\n",
       "      <td>2.510893</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.112391</td>\n",
       "      <td>-0.070020</td>\n",
       "      <td>0.894871</td>\n",
       "      <td>-1.614532</td>\n",
       "      <td>2.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.492223</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.701386</td>\n",
       "      <td>-1.081667</td>\n",
       "      <td>-1.144499</td>\n",
       "      <td>-1.346349</td>\n",
       "      <td>2.000033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.50552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_pipeline__Age  num_pipeline__Subscription_Length_Months  \\\n",
       "0          -1.243589                                  0.074501   \n",
       "1           0.654284                                 -1.515230   \n",
       "2          -0.785482                                  1.086147   \n",
       "3           1.112391                                 -0.070020   \n",
       "4           1.701386                                 -1.081667   \n",
       "\n",
       "   num_pipeline__Monthly_Bill  num_pipeline__Total_Usage_GB  \\\n",
       "0                    1.632642                      1.481066   \n",
       "1                    0.336478                      0.829765   \n",
       "2                    0.027632                      1.166909   \n",
       "3                    0.894871                     -1.614532   \n",
       "4                   -1.144499                     -1.346349   \n",
       "\n",
       "   cat_pipeline__Gender_Female  cat_pipeline__Gender_Male  \\\n",
       "0                     0.000000                   2.000033   \n",
       "1                     2.000033                   0.000000   \n",
       "2                     0.000000                   2.000033   \n",
       "3                     2.000033                   0.000000   \n",
       "4                     2.000033                   0.000000   \n",
       "\n",
       "   cat_pipeline__Location_Chicago  cat_pipeline__Location_Houston  \\\n",
       "0                        0.000000                        0.000000   \n",
       "1                        0.000000                        2.492223   \n",
       "2                        2.510893                        0.000000   \n",
       "3                        0.000000                        2.492223   \n",
       "4                        0.000000                        0.000000   \n",
       "\n",
       "   cat_pipeline__Location_Los Angeles  cat_pipeline__Location_Miami  \\\n",
       "0                            2.499063                           0.0   \n",
       "1                            0.000000                           0.0   \n",
       "2                            0.000000                           0.0   \n",
       "3                            0.000000                           0.0   \n",
       "4                            0.000000                           0.0   \n",
       "\n",
       "   cat_pipeline__Location_New York  \n",
       "0                          0.00000  \n",
       "1                          0.00000  \n",
       "2                          0.00000  \n",
       "3                          0.00000  \n",
       "4                          2.50552  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix, precision_score, recall_score, precision_recall_curve, roc_curve, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    # 'Logistic Regression': LogisticRegression(random_state=42),\n",
    "    # 'SGDClassifier': SGDClassifier(),\n",
    "    # 'DecisionTreeClassifier': DecisionTreeClassifier(random_state=42),\n",
    "    # 'SVC linear': SVC(kernel='linear'),\n",
    "    # 'SVC rbf': SVC(kernel='rbf'),\n",
    "    # 'NaiveBias':MultinomialNB(),\n",
    "    'KNNR':KNeighborsClassifier(n_neighbors=2),\n",
    "   \n",
    "    # 'RandomForest':RandomForestClassifier(random_state=42),\n",
    "    # 'AdaBoost':AdaBoostClassifier(),\n",
    "    # 'Gradient Boosting':GradientBoostingClassifier(),\n",
    "    # 'XGB':xgb.XGBClassifier(),\n",
    "    # 'BaggingSVC':BaggingClassifier(estimator=SVC())\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNNR\n",
      "Model Training Performance\n",
      "Score 49.95666666666666\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_model_list = {'Model_Name':[], 'Model': [], 'Score': []}\n",
    "\n",
    "for i in range(len(list(models))):\n",
    "    model=list(models.values())[i]\n",
    "\n",
    "    # Train  on training data\n",
    "    model.fit(X_train,y_train)\n",
    "\n",
    "    #Make Predictions\n",
    "    y_pred=model.predict(X_test)\n",
    "\n",
    "    score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "\n",
    "    print(list(models.keys())[i])\n",
    "\n",
    "    print('Model Training Performance')\n",
    "    print(\"Score\",score*100)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    cm_dis = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=model.classes_)\n",
    "    cm_dis.plot()\n",
    "    plt.show()\n",
    "\n",
    "    trained_model_list['Model_Name'].append(list(models.keys())[i])\n",
    "    trained_model_list['Model'].append(model)\n",
    "    trained_model_list['Score'].append(score*100)\n",
    "\n",
    "    # trained_model_list.update({'Model_Name': list(models.keys())[i], 'Model': model, 'R2_Score': r2_square*100})\n",
    "\n",
    "    print('='*35)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNNR</td>\n",
       "      <td>KNeighborsClassifier(n_neighbors=2)</td>\n",
       "      <td>49.956667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model_Name                                Model      Score\n",
       "0       KNNR  KNeighborsClassifier(n_neighbors=2)  49.956667"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trained_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model_Name</th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>LogisticRegression(random_state=42)</td>\n",
       "      <td>50.466667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>SGDClassifier()</td>\n",
       "      <td>50.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>DecisionTreeClassifier(random_state=42)</td>\n",
       "      <td>49.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC linear</td>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>50.546667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC rbf</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>50.246667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='sqrt', r...</td>\n",
       "      <td>49.406667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "      <td>50.420000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "      <td>50.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGB</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>50.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BaggingSVC</td>\n",
       "      <td>(SVC(random_state=236708574), SVC(random_state...</td>\n",
       "      <td>50.510000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model_Name                                              Model  \\\n",
       "0     Logistic Regression                LogisticRegression(random_state=42)   \n",
       "1           SGDClassifier                                    SGDClassifier()   \n",
       "2  DecisionTreeClassifier            DecisionTreeClassifier(random_state=42)   \n",
       "3              SVC linear                               SVC(kernel='linear')   \n",
       "4                 SVC rbf                                              SVC()   \n",
       "5            RandomForest  (DecisionTreeClassifier(max_features='sqrt', r...   \n",
       "6                AdaBoost  (DecisionTreeClassifier(max_depth=1, random_st...   \n",
       "7       Gradient Boosting  ([DecisionTreeRegressor(criterion='friedman_ms...   \n",
       "8                     XGB  XGBClassifier(base_score=None, booster=None, c...   \n",
       "9              BaggingSVC  (SVC(random_state=236708574), SVC(random_state...   \n",
       "\n",
       "       Score  \n",
       "0  50.466667  \n",
       "1  50.450000  \n",
       "2  49.930000  \n",
       "3  50.546667  \n",
       "4  50.246667  \n",
       "5  49.406667  \n",
       "6  50.420000  \n",
       "7  50.230000  \n",
       "8  50.450000  \n",
       "9  50.510000  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(trained_model_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model that can be used for inference only\n",
      "Using a Transformer with 25.82 M parameters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TabPFNClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TabPFNClassifier</label><div class=\"sk-toggleable__content\"><pre>TabPFNClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TabPFNClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tabpfn import TabPFNClassifier\n",
    "model = TabPFNClassifier()\n",
    "model.fit(X_train, y_train, overwrite_warning=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 235200000000 bytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y_pred \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(X_test)\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:287\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict\u001b[1;34m(self, X, return_winning_probability, normalize_with_test)\u001b[0m\n\u001b[0;32m    286\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X, return_winning_probability\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, normalize_with_test\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m--> 287\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X, normalize_with_test\u001b[39m=\u001b[39;49mnormalize_with_test)\n\u001b[0;32m    288\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margmax(p, axis\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m    289\u001b[0m     y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39masarray(y, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mintp))\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:266\u001b[0m, in \u001b[0;36mTabPFNClassifier.predict_proba\u001b[1;34m(self, X, normalize_with_test, return_logits)\u001b[0m\n\u001b[0;32m    262\u001b[0m y_full \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(y_full, device\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39mfloat()\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m    264\u001b[0m eval_pos \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m--> 266\u001b[0m prediction \u001b[39m=\u001b[39m transformer_predict(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel[\u001b[39m2\u001b[39;49m], X_full, y_full, eval_pos,\n\u001b[0;32m    267\u001b[0m                                  device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice,\n\u001b[0;32m    268\u001b[0m                                  style\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstyle,\n\u001b[0;32m    269\u001b[0m                                  inference_mode\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    270\u001b[0m                                  preprocess_transform\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mnone\u001b[39;49m\u001b[39m'\u001b[39;49m \u001b[39mif\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mno_preprocess_mode \u001b[39melse\u001b[39;49;00m \u001b[39m'\u001b[39;49m\u001b[39mmix\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m    271\u001b[0m                                  normalize_with_test\u001b[39m=\u001b[39;49mnormalize_with_test,\n\u001b[0;32m    272\u001b[0m                                  N_ensemble_configurations\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mN_ensemble_configurations,\n\u001b[0;32m    273\u001b[0m                                  softmax_temperature\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemperature,\n\u001b[0;32m    274\u001b[0m                                  multiclass_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmulticlass_decoder,\n\u001b[0;32m    275\u001b[0m                                  feature_shift_decoder\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeature_shift_decoder,\n\u001b[0;32m    276\u001b[0m                                  differentiable_hps_as_style\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdifferentiable_hps_as_style,\n\u001b[0;32m    277\u001b[0m                                  seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed,\n\u001b[0;32m    278\u001b[0m                                  return_logits\u001b[39m=\u001b[39;49mreturn_logits,\n\u001b[0;32m    279\u001b[0m                                  no_grad\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mno_grad,\n\u001b[0;32m    280\u001b[0m                                  batch_size_inference\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size_inference,\n\u001b[0;32m    281\u001b[0m                                  \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mget_params_from_config(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mc))\n\u001b[0;32m    282\u001b[0m prediction_, y_ \u001b[39m=\u001b[39m prediction\u001b[39m.\u001b[39msqueeze(\u001b[39m0\u001b[39m), y_full\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mlong()[eval_pos:]\n\u001b[0;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m prediction_\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mno_grad \u001b[39melse\u001b[39;00m prediction_\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:517\u001b[0m, in \u001b[0;36mtransformer_predict\u001b[1;34m(model, eval_xs, eval_ys, eval_position, device, max_features, style, inference_mode, num_classes, extend_features, normalize_with_test, normalize_to_ranking, softmax_temperature, multiclass_decoder, preprocess_transform, categorical_feats, feature_shift_decoder, N_ensemble_configurations, batch_size_inference, differentiable_hps_as_style, average_logits, fp16_inference, normalize_with_sqrt, seed, no_grad, return_logits, **kwargs)\u001b[0m\n\u001b[0;32m    514\u001b[0m warnings\u001b[39m.\u001b[39mfilterwarnings(\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    515\u001b[0m                         message\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtorch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    516\u001b[0m \u001b[39mif\u001b[39;00m device \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> 517\u001b[0m     output_batch \u001b[39m=\u001b[39m checkpoint(predict, batch_input, batch_label, style_, softmax_temperature_, \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    518\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    519\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mamp\u001b[39m.\u001b[39mautocast(enabled\u001b[39m=\u001b[39mfp16_inference):\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:249\u001b[0m, in \u001b[0;36mcheckpoint\u001b[1;34m(function, use_reentrant, *args, **kwargs)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mUnexpected keyword arguments: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(arg \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m kwargs))\n\u001b[0;32m    248\u001b[0m \u001b[39mif\u001b[39;00m use_reentrant:\n\u001b[1;32m--> 249\u001b[0m     \u001b[39mreturn\u001b[39;00m CheckpointFunction\u001b[39m.\u001b[39;49mapply(function, preserve, \u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    250\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    251\u001b[0m     \u001b[39mreturn\u001b[39;00m _checkpoint_without_reentrant(\n\u001b[0;32m    252\u001b[0m         function,\n\u001b[0;32m    253\u001b[0m         preserve,\n\u001b[0;32m    254\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[0;32m    255\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    256\u001b[0m     )\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\autograd\\function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[0;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[0;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[1;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[0;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\utils\\checkpoint.py:107\u001b[0m, in \u001b[0;36mCheckpointFunction.forward\u001b[1;34m(ctx, run_function, preserve_rng_state, *args)\u001b[0m\n\u001b[0;32m    104\u001b[0m ctx\u001b[39m.\u001b[39msave_for_backward(\u001b[39m*\u001b[39mtensor_inputs)\n\u001b[0;32m    106\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m--> 107\u001b[0m     outputs \u001b[39m=\u001b[39m run_function(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m    108\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\scripts\\transformer_prediction_interface.py:353\u001b[0m, in \u001b[0;36mtransformer_predict.<locals>.predict\u001b[1;34m(eval_xs, eval_ys, used_style, softmax_temperature, return_logits)\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[39mwith\u001b[39;00m inference_mode_call:\n\u001b[0;32m    352\u001b[0m     start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m--> 353\u001b[0m     output \u001b[39m=\u001b[39m model(\n\u001b[0;32m    354\u001b[0m             (used_style\u001b[39m.\u001b[39;49mrepeat(eval_xs\u001b[39m.\u001b[39;49mshape[\u001b[39m1\u001b[39;49m], \u001b[39m1\u001b[39;49m) \u001b[39mif\u001b[39;49;00m used_style \u001b[39mis\u001b[39;49;00m \u001b[39mnot\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, eval_xs, eval_ys\u001b[39m.\u001b[39;49mfloat()),\n\u001b[0;32m    355\u001b[0m             single_eval_pos\u001b[39m=\u001b[39;49meval_position)[:, :, \u001b[39m0\u001b[39m:num_classes]\n\u001b[0;32m    357\u001b[0m     output \u001b[39m=\u001b[39m output[:, :, \u001b[39m0\u001b[39m:num_classes] \u001b[39m/\u001b[39m torch\u001b[39m.\u001b[39mexp(softmax_temperature)\n\u001b[0;32m    358\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m return_logits:\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\transformer.py:141\u001b[0m, in \u001b[0;36mTransformerModel.forward\u001b[1;34m(self, src, src_mask, single_eval_pos)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     src \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpos_encoder(src)\n\u001b[1;32m--> 141\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer_encoder(src, src_mask)\n\u001b[0;32m    142\u001b[0m output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecoder(output)\n\u001b[0;32m    143\u001b[0m \u001b[39mreturn\u001b[39;00m output[single_eval_pos\u001b[39m+\u001b[39m\u001b[39mlen\u001b[39m(style_src)\u001b[39m+\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_att_embeddings\u001b[39m.\u001b[39mnum_embeddings \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mglobal_att_embeddings \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m):]\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\transformer.py:227\u001b[0m, in \u001b[0;36mTransformerEncoderDiffInit.forward\u001b[1;34m(self, src, mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    224\u001b[0m output \u001b[39m=\u001b[39m src\n\u001b[0;32m    226\u001b[0m \u001b[39mfor\u001b[39;00m mod \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers:\n\u001b[1;32m--> 227\u001b[0m     output \u001b[39m=\u001b[39m mod(output, src_mask\u001b[39m=\u001b[39;49mmask, src_key_padding_mask\u001b[39m=\u001b[39;49msrc_key_padding_mask)\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm(output)\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\tabpfn\\layer.py:108\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[1;34m(self, src, src_mask, src_key_padding_mask)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[39massert\u001b[39;00m src_key_padding_mask \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    107\u001b[0m single_eval_position \u001b[39m=\u001b[39m src_mask\n\u001b[1;32m--> 108\u001b[0m src_left \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mself_attn(src_[:single_eval_position], src_[:single_eval_position], src_[:single_eval_position])[\u001b[39m0\u001b[39m]\n\u001b[0;32m    109\u001b[0m src_right \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mself_attn(src_[single_eval_position:], src_[:single_eval_position], src_[:single_eval_position])[\u001b[39m0\u001b[39m]\n\u001b[0;32m    110\u001b[0m src2 \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([src_left, src_right], dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\modules\\activation.py:1205\u001b[0m, in \u001b[0;36mMultiheadAttention.forward\u001b[1;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mmulti_head_attention_forward(\n\u001b[0;32m   1192\u001b[0m         query, key, value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_heads,\n\u001b[0;32m   1193\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_weight, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39min_proj_bias,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1202\u001b[0m         average_attn_weights\u001b[39m=\u001b[39maverage_attn_weights,\n\u001b[0;32m   1203\u001b[0m         is_causal\u001b[39m=\u001b[39mis_causal)\n\u001b[0;32m   1204\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 1205\u001b[0m     attn_output, attn_output_weights \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mmulti_head_attention_forward(\n\u001b[0;32m   1206\u001b[0m         query, key, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_heads,\n\u001b[0;32m   1207\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_weight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49min_proj_bias,\n\u001b[0;32m   1208\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_k, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias_v, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madd_zero_attn,\n\u001b[0;32m   1209\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mout_proj\u001b[39m.\u001b[39;49mbias,\n\u001b[0;32m   1210\u001b[0m         training\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining,\n\u001b[0;32m   1211\u001b[0m         key_padding_mask\u001b[39m=\u001b[39;49mkey_padding_mask,\n\u001b[0;32m   1212\u001b[0m         need_weights\u001b[39m=\u001b[39;49mneed_weights,\n\u001b[0;32m   1213\u001b[0m         attn_mask\u001b[39m=\u001b[39;49mattn_mask,\n\u001b[0;32m   1214\u001b[0m         average_attn_weights\u001b[39m=\u001b[39;49maverage_attn_weights,\n\u001b[0;32m   1215\u001b[0m         is_causal\u001b[39m=\u001b[39;49mis_causal)\n\u001b[0;32m   1216\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first \u001b[39mand\u001b[39;00m is_batched:\n\u001b[0;32m   1217\u001b[0m     \u001b[39mreturn\u001b[39;00m attn_output\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m), attn_output_weights\n",
      "File \u001b[1;32md:\\Data Science\\Job Assignments\\SunBaseData\\venv\\lib\\site-packages\\torch\\nn\\functional.py:5338\u001b[0m, in \u001b[0;36mmulti_head_attention_forward\u001b[1;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[0;32m   5336\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mbaddbmm(attn_mask, q_scaled, k\u001b[39m.\u001b[39mtranspose(\u001b[39m-\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[0;32m   5337\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 5338\u001b[0m     attn_output_weights \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mbmm(q_scaled, k\u001b[39m.\u001b[39;49mtranspose(\u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m))\n\u001b[0;32m   5339\u001b[0m attn_output_weights \u001b[39m=\u001b[39m softmax(attn_output_weights, dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m   5340\u001b[0m \u001b[39mif\u001b[39;00m dropout_p \u001b[39m>\u001b[39m \u001b[39m0.0\u001b[39m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\c10\\core\\impl\\alloc_cpu.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 235200000000 bytes."
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
